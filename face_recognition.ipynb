{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e506fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f671e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "dfgd (13, 30000)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./'\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        continue\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(gray_frame,1.3,5)\n",
    "    faces = sorted(faces,key=lambda f:f[2]*f[3])\n",
    "    \n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h=face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        offset=10\n",
    "        fs=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        fs=cv2.resize(fs,(100,100))\n",
    "        skip+=1\n",
    "        if skip%10==0:\n",
    "            face_data.append(fs)\n",
    "            print(len(face_data))\n",
    "        \n",
    "    \n",
    "#     print(faces)\n",
    "    \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow('fs',fs)\n",
    "    key_pressed = cv2.waitKey(1) & 0XFF\n",
    "    if key_pressed ==ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "face_data=np.array(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "np.save('bhupat',face_data)\n",
    "print('dfgd',face_data.shape)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71221021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(v1,v2):\n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "def knn(train,test,k=5):\n",
    "    dist=[]\n",
    "    for i in range(train.shape[0]):\n",
    "        ix=train[i,:-1]\n",
    "        iy=train[i,-1]\n",
    "        d=distance(test,ix)\n",
    "        dist.append([d,iy])\n",
    "        \n",
    "    dk=sorted(dist,key=lambda x:x[0])[:k]\n",
    "    lables=np.array(dk)[:,-1]\n",
    "    output=np.unique(lables,return_counts=True)\n",
    "    index=np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "cap=cv2.VideoCapture(0)\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./'\n",
    "label=[]\n",
    "class_id=0\n",
    "names={}\n",
    "\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        names[class_id]=fx[:-4]\n",
    "        data_item=np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        target=class_id * np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        label.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data,axis=0)\n",
    "face_labels = np.concatenate(label,axis=0)\n",
    "\n",
    "face_labels=face_labels.reshape((-1,1))\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "# print(face_dataset.shape)\n",
    "# print(face_labels.shape)\n",
    "# print(trainset.shape)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==False:\n",
    "        continue\n",
    "#     gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "\n",
    "    for face in faces:\n",
    "        x,y,w,h=face\n",
    "        offset=10\n",
    "        face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "#         knn = KNeighborsClassifier(n_neighbors=3)\n",
    "#         knn.fit(trainset,face_section.flatten())\n",
    "#         out=knn.predict(x_test)\n",
    "        out=knn(trainset,face_section.flatten())\n",
    "        \n",
    "        pred_name=names[int(out)]\n",
    "        \n",
    "        cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "    cv2.imshow('Faces',frame)\n",
    "    key_pressed = cv2.waitKey(1) & 0XFF\n",
    "    if key_pressed ==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f380bd5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9632/4063986947.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\BHUPAT~1\\AppData\\Local\\Temp/ipykernel_9632/4063986947.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from cv2 import\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from cv2 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20620d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566d27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6207c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f97f9cda",
   "metadata": {},
   "source": [
    "06-06-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eaa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ac14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "def distance(v1,v2):\n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "def knn(train,test,k=5):\n",
    "    dist=[]\n",
    "    for i in range(train.shape[0]):\n",
    "        ix=train[i,:-1]\n",
    "        iy=train[i,-1]\n",
    "        d=distance(test,ix)\n",
    "        dist.append([d,iy])\n",
    "        \n",
    "    dk=sorted(dist,key=lambda x:x[0])[:k]\n",
    "    lables=np.array(dk)[:,-1]\n",
    "    output=np.unique(lables,return_counts=True)\n",
    "    index=np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "cap=cv2.VideoCapture(0)\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./'\n",
    "label=[]\n",
    "class_id=0\n",
    "names={}\n",
    "\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        names[class_id]=fx[:-4]\n",
    "        data_item=np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        target=class_id * np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        label.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data,axis=0)\n",
    "face_labels = np.concatenate(label,axis=0)\n",
    "\n",
    "face_labels=face_labels.reshape((-1,1))\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "# print(face_dataset.shape)\n",
    "# print(face_labels.shape)\n",
    "# print(trainset.shape)\n",
    "\n",
    "# foreground = np.ones((100,100,3),dtype='uint8')*255\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==False:\n",
    "        continue\n",
    "#     gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    \n",
    "    for face in faces:\n",
    "        x,y,w,h=face\n",
    "        offset=10\n",
    "        face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "        out=knn(trainset,face_section.flatten())\n",
    "        \n",
    "        pred_name=names[int(out)]\n",
    "        \n",
    "        cv2.putText(frame,pred_name,(x,y+h-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        foreground = cv2.imread(pred_name+'.png')\n",
    "        alpha = 0.4\n",
    "    \n",
    "    \n",
    "#         added_image = cv2.addWeighted(frame[150:250,150:250,:],alpha,foreground[0:100,0:100,:],1-alpha,0)\n",
    "#         frame[150:250,150:250] = added_image\n",
    "        added_image = cv2.addWeighted(frame[y-50:y,x:x+w,:],alpha,foreground[0:50,0:w,:],1-alpha,0)\n",
    "        \n",
    "        frame[y-50:y,x:x+w] = added_image\n",
    "        \n",
    "    \n",
    "    \n",
    "    cv2.imshow('Faces',frame)\n",
    "    key_pressed = cv2.waitKey(1) & 0XFF\n",
    "    if key_pressed ==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe30c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# create an overlay image. You can use any image\n",
    "foreground = np.ones((100,100,3),dtype='uint8')*255\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set initial value of weights\n",
    "alpha = 0.4\n",
    "while True:\n",
    "    ret, background = cap.read()\n",
    "    added_image = cv2.addWeighted(background[150:250,150:250,:],alpha,foreground[0:100,0:100,:],1-alpha,0)\n",
    "    background[150:250,150:250] = added_image\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(background,'alpha:{}'.format(alpha),(10,30), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('a',background)\n",
    "    k = cv2.waitKey(10)\n",
    "    \n",
    "    if k == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170da06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
